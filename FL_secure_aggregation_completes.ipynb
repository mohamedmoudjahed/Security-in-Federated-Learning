{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Federated Learning avec Secure Aggregation Complète et RSA\n",
    "\n",
    "## Fonctionnalités implémentées:\n",
    "\n",
    "1. **Transmission des mises à jour (Δw)** au lieu des poids complets\n",
    "2. **Signature RSA réelle** pour l'authentification des clients\n",
    "3. **Secure Aggregation avec:**\n",
    "   - Protocole Diffie-Hellman pour génération de clés partagées\n",
    "   - Masquage pairwise (chaque client masque avec tous les autres)\n",
    "   - SHA256 pour dériver des graines (seeds) déterministes\n",
    "   - Génération de masques aléatoires déterministes via PRG\n",
    "4. **Vérification des signatures** côté serveur avant agrégation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Imports réussis\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cryptographie\n",
    "from cryptography.hazmat.primitives.asymmetric import rsa, padding\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import hashlib\n",
    "import pickle\n",
    "\n",
    "# Seeds\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "print(\" Imports réussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rsa_class",
   "metadata": {},
   "source": [
    "## 1. Classe RSA pour l'Authentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "rsa_manager",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classe RSAManager définie\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CLASSE RSA POUR AUTHENTIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "class RSAManager:\n",
    "    \"\"\"\n",
    "    Gestionnaire de clés RSA pour l'authentification des clients.\n",
    "    Chaque client possède une paire de clés (publique/privée).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client_keys = {}  # {client_id: {'private': key, 'public': key}}\n",
    "    \n",
    "    def generate_keypair(self, client_id):\n",
    "        \"\"\"Génère une paire de clés RSA 2048 bits pour un client.\"\"\"\n",
    "        private_key = rsa.generate_private_key(\n",
    "            public_exponent=65537,\n",
    "            key_size=2048,\n",
    "            backend=default_backend()\n",
    "        )\n",
    "        public_key = private_key.public_key()\n",
    "        \n",
    "        self.client_keys[client_id] = {\n",
    "            'private': private_key,\n",
    "            'public': public_key\n",
    "        }\n",
    "        \n",
    "        return private_key, public_key\n",
    "    \n",
    "    def get_private_key(self, client_id):\n",
    "        \"\"\"Récupère la clé privée d'un client.\"\"\"\n",
    "        return self.client_keys[client_id]['private']\n",
    "    \n",
    "    def get_public_key(self, client_id):\n",
    "        \"\"\"Récupère la clé publique d'un client.\"\"\"\n",
    "        return self.client_keys[client_id]['public']\n",
    "    \n",
    "    def sign_data(self, data, private_key):\n",
    "        \"\"\"\n",
    "        Signe des données avec une clé privée RSA.\n",
    "        Utilise PSS padding et SHA256.\n",
    "        \n",
    "        Args:\n",
    "            data: Données à signer (list of numpy arrays)\n",
    "            private_key: Clé privée RSA\n",
    "        \n",
    "        Returns:\n",
    "            signature: bytes\n",
    "        \"\"\"\n",
    "        # Sérialiser les données\n",
    "        data_bytes = pickle.dumps([arr.tolist() for arr in data])\n",
    "        \n",
    "        # Hasher les données\n",
    "        data_hash = hashlib.sha256(data_bytes).digest()\n",
    "        \n",
    "        # Signer le hash\n",
    "        signature = private_key.sign(\n",
    "            data_hash,\n",
    "            padding.PSS(\n",
    "                mgf=padding.MGF1(hashes.SHA256()),\n",
    "                salt_length=padding.PSS.MAX_LENGTH\n",
    "            ),\n",
    "            hashes.SHA256()\n",
    "        )\n",
    "        \n",
    "        return signature\n",
    "    \n",
    "    def verify_signature(self, data, signature, public_key):\n",
    "        \"\"\"\n",
    "        Vérifie une signature RSA.\n",
    "        \n",
    "        Args:\n",
    "            data: Données originales (list of numpy arrays)\n",
    "            signature: Signature à vérifier\n",
    "            public_key: Clé publique RSA\n",
    "        \n",
    "        Returns:\n",
    "            bool: True si signature valide, False sinon\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Recalculer le hash des données\n",
    "            data_bytes = pickle.dumps([arr.tolist() for arr in data])\n",
    "            data_hash = hashlib.sha256(data_bytes).digest()\n",
    "            \n",
    "            # Vérifier la signature\n",
    "            public_key.verify(\n",
    "                signature,\n",
    "                data_hash,\n",
    "                padding.PSS(\n",
    "                    mgf=padding.MGF1(hashes.SHA256()),\n",
    "                    salt_length=padding.PSS.MAX_LENGTH\n",
    "                ),\n",
    "                hashes.SHA256()\n",
    "            )\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "print(\" Classe RSAManager définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secagg_class",
   "metadata": {},
   "source": [
    "## 2. Classe Secure Aggregation (Diffie-Hellman + Masquage Pairwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "secure_aggregation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classe SecureAggregation définie\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CLASSE SECURE AGGREGATION\n",
    "# =============================================================================\n",
    "\n",
    "class SecureAggregation:\n",
    "    \"\"\"\n",
    "    Implémentation de Secure Aggregation avec:\n",
    "    - Diffie-Hellman pour l'échange de clés\n",
    "    - SHA256 pour dériver des seeds\n",
    "    - Masquage pairwise déterministe\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_clients):\n",
    "        self.num_clients = num_clients\n",
    "        # Paramètres Diffie-Hellman (nombre premier sûr)\n",
    "        self.p = 2**61 - 1  # Nombre premier de Mersenne (suffisant pour démo)\n",
    "        self.g = 2  # Générateur\n",
    "        \n",
    "        # Clés privées DH pour chaque client\n",
    "        self.private_keys = {}\n",
    "        # Clés publiques DH pour chaque client\n",
    "        self.public_keys = {}\n",
    "        \n",
    "        # Graines partagées (seeds) entre paires de clients\n",
    "        self.shared_seeds = {}\n",
    "    \n",
    "    def generate_dh_keypair(self, client_id):\n",
    "        \"\"\"\n",
    "        Génère une paire de clés Diffie-Hellman pour un client.\n",
    "        \n",
    "        Returns:\n",
    "            (private_key, public_key)\n",
    "        \"\"\"\n",
    "        # Clé privée: nombre aléatoire (utiliser secrets pour les grands nombres)\n",
    "        import secrets\n",
    "        private_key = secrets.randbelow(self.p - 2) + 2\n",
    "        # Clé publique: g^private mod p\n",
    "        public_key = pow(self.g, private_key, self.p)\n",
    "        \n",
    "        self.private_keys[client_id] = private_key\n",
    "        self.public_keys[client_id] = public_key\n",
    "        \n",
    "        return private_key, public_key\n",
    "    \n",
    "    def compute_shared_seed(self, client_i, client_j, public_key_j):\n",
    "        \"\"\"\n",
    "        Calcule la graine partagée entre deux clients via Diffie-Hellman.\n",
    "        \n",
    "        Args:\n",
    "            client_i: ID du client local\n",
    "            client_j: ID du client distant\n",
    "            public_key_j: Clé publique DH du client j\n",
    "        \n",
    "        Returns:\n",
    "            seed: int (graine dérivée via SHA256)\n",
    "        \"\"\"\n",
    "        # Secret partagé DH: (g^b)^a = g^(ab) mod p\n",
    "        private_key_i = self.private_keys[client_i]\n",
    "        shared_secret = pow(public_key_j, private_key_i, self.p)\n",
    "        \n",
    "        # Dériver une graine via SHA256\n",
    "        shared_bytes = str(shared_secret).encode()\n",
    "        seed_hash = hashlib.sha256(shared_bytes).digest()\n",
    "        # Convertir en entier pour seed numpy\n",
    "        seed = int.from_bytes(seed_hash[:4], byteorder='big')\n",
    "        \n",
    "        return seed\n",
    "    \n",
    "    def generate_pairwise_mask(self, seed, shape):\n",
    "        \"\"\"\n",
    "        Génère un masque aléatoire déterministe à partir d'une graine.\n",
    "        \n",
    "        Args:\n",
    "            seed: Graine pour le générateur aléatoire\n",
    "            shape: Forme du masque\n",
    "        \n",
    "        Returns:\n",
    "            mask: numpy array\n",
    "        \"\"\"\n",
    "        # Créer un générateur avec la graine\n",
    "        rng = np.random.RandomState(seed)\n",
    "        # Masque aléatoire gaussien\n",
    "        mask = rng.randn(*shape) * 0.1\n",
    "        return mask\n",
    "    \n",
    "    def mask_weights(self, client_id, weight_updates):\n",
    "        \"\"\"\n",
    "        Masque les mises à jour de poids avec masquage pairwise.\n",
    "        \n",
    "        Pour chaque autre client j:\n",
    "        - Si i < j: ajoute le masque +M_ij\n",
    "        - Si i > j: ajoute le masque -M_ij\n",
    "        \n",
    "        Ainsi, lors de l'agrégation, les masques s'annulent:\n",
    "        M_ij - M_ij = 0\n",
    "        \n",
    "        Args:\n",
    "            client_id: ID du client\n",
    "            weight_updates: Liste des mises à jour de poids (Δw)\n",
    "        \n",
    "        Returns:\n",
    "            masked_updates: Liste des mises à jour masquées\n",
    "        \"\"\"\n",
    "        masked_updates = [w.copy() for w in weight_updates]\n",
    "        \n",
    "        # Pour chaque autre client\n",
    "        for other_id in range(self.num_clients):\n",
    "            if other_id == client_id:\n",
    "                continue\n",
    "            \n",
    "            # Récupérer la clé publique de l'autre client\n",
    "            public_key_other = self.public_keys[other_id]\n",
    "            \n",
    "            # Calculer la graine partagée\n",
    "            seed = self.compute_shared_seed(client_id, other_id, public_key_other)\n",
    "            \n",
    "            # Générer et appliquer les masques pour chaque couche\n",
    "            for layer_idx, update in enumerate(masked_updates):\n",
    "                mask = self.generate_pairwise_mask(seed + layer_idx, update.shape)\n",
    "                \n",
    "                # Ajouter ou soustraire selon l'ordre des IDs\n",
    "                if client_id < other_id:\n",
    "                    masked_updates[layer_idx] += mask\n",
    "                else:\n",
    "                    masked_updates[layer_idx] -= mask\n",
    "        \n",
    "        return masked_updates\n",
    "\n",
    "print(\" Classe SecureAggregation définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "NUM_CLIENTS = 20\n",
    "NUM_ROUNDS = 5\n",
    "LOCAL_EPOCHS = 1 \n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data",
   "metadata": {},
   "source": [
    "## 4. Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Données chargées:\n",
      "  - Train: (60000, 28, 28, 1)\n",
      "  - Test: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CHARGEMENT DES DONNÉES MNIST\n",
    "# =============================================================================\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalisation\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Reshape\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(f\" Données chargées:\")\n",
    "print(f\"  - Train: {x_train.shape}\")\n",
    "print(f\"  - Test: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partition",
   "metadata": {},
   "source": [
    "## 5. Partitionnement des Données (IID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "partition_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Données distribuées à 20 clients\n",
      "  - Échantillons par client: 3000\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PARTITIONNEMENT DES DONNÉES\n",
    "# =============================================================================\n",
    "\n",
    "def create_iid_clients(x_train, y_train, num_clients):\n",
    "    \"\"\"Distribue les données de manière IID entre les clients.\"\"\"\n",
    "    indices = np.random.permutation(len(x_train))\n",
    "    samples_per_client = len(x_train) // num_clients\n",
    "    \n",
    "    client_data = []\n",
    "    for i in range(num_clients):\n",
    "        start_idx = i * samples_per_client\n",
    "        end_idx = start_idx + samples_per_client\n",
    "        \n",
    "        client_indices = indices[start_idx:end_idx]\n",
    "        client_x = x_train[client_indices]\n",
    "        client_y = y_train[client_indices]\n",
    "        \n",
    "        client_data.append((client_x, client_y))\n",
    "    \n",
    "    return client_data\n",
    "\n",
    "client_datasets = create_iid_clients(x_train, y_train, NUM_CLIENTS)\n",
    "print(f\" Données distribuées à {NUM_CLIENTS} clients\")\n",
    "print(f\"  - Échantillons par client: {len(client_datasets[0][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model",
   "metadata": {},
   "source": [
    "## 6. Définition du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "create_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Architecture du modèle définie\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODÈLE CNN\n",
    "# =============================================================================\n",
    "\n",
    "def create_cnn_model():\n",
    "    \"\"\"Crée un modèle CNN simple pour MNIST.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\" Architecture du modèle définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fl_class",
   "metadata": {},
   "source": [
    "## 7. Classe Client FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "client_class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classe FederatedClient définie\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CLASSE CLIENT\n",
    "# =============================================================================\n",
    "\n",
    "class FederatedClient:\n",
    "    \"\"\"\n",
    "    Client de Federated Learning avec:\n",
    "    - Entraînement local\n",
    "    - Calcul des mises à jour (Δw)\n",
    "    - Masquage des mises à jour\n",
    "    - Signature RSA\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, client_id, data, rsa_manager, sec_agg):\n",
    "        self.client_id = client_id\n",
    "        self.x_train, self.y_train = data\n",
    "        self.rsa_manager = rsa_manager\n",
    "        self.sec_agg = sec_agg\n",
    "        \n",
    "        # Modèle local\n",
    "        self.model = create_cnn_model()\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        \"\"\"Reçoit les poids globaux du serveur.\"\"\"\n",
    "        self.model.set_weights(weights)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        \"\"\"Retourne les poids actuels.\"\"\"\n",
    "        return self.model.get_weights()\n",
    "    \n",
    "    def train(self, epochs=1, batch_size=32, verbose=0):\n",
    "        \"\"\"Entraîne le modèle localement.\"\"\"\n",
    "        self.model.fit(\n",
    "            self.x_train, self.y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=verbose\n",
    "        )\n",
    "    \n",
    "    def compute_weight_update(self, global_weights):\n",
    "        \"\"\"\n",
    "        Calcule la mise à jour des poids: Δw = w_local - w_global\n",
    "        \n",
    "        Args:\n",
    "            global_weights: Poids globaux du serveur\n",
    "        \n",
    "        Returns:\n",
    "            weight_update: Liste de numpy arrays (Δw)\n",
    "        \"\"\"\n",
    "        local_weights = self.get_weights()\n",
    "        weight_update = [\n",
    "            local_w - global_w \n",
    "            for local_w, global_w in zip(local_weights, global_weights)\n",
    "        ]\n",
    "        return weight_update\n",
    "    \n",
    "    def prepare_update(self, global_weights):\n",
    "        \"\"\"\n",
    "        Prépare la mise à jour complète:\n",
    "        1. Calcule Δw\n",
    "        2. Masque Δw\n",
    "        3. Signe Δw masqué\n",
    "        \n",
    "        Returns:\n",
    "            (masked_update, signature)\n",
    "        \"\"\"\n",
    "        # 1. Calculer Δw\n",
    "        weight_update = self.compute_weight_update(global_weights)\n",
    "        \n",
    "        # 2. Masquer Δw\n",
    "        masked_update = self.sec_agg.mask_weights(self.client_id, weight_update)\n",
    "        \n",
    "        # 3. Signer Δw masqué\n",
    "        private_key = self.rsa_manager.get_private_key(self.client_id)\n",
    "        signature = self.rsa_manager.sign_data(masked_update, private_key)\n",
    "        \n",
    "        return masked_update, signature\n",
    "\n",
    "print(\" Classe FederatedClient définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "server_class",
   "metadata": {},
   "source": [
    "## 8. Classe Serveur FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "server_class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classe FederatedServer définie\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CLASSE SERVEUR\n",
    "# =============================================================================\n",
    "\n",
    "class FederatedServer:\n",
    "    \"\"\"\n",
    "    Serveur de Federated Learning avec:\n",
    "    - Vérification des signatures RSA\n",
    "    - Agrégation des mises à jour masquées\n",
    "    - Mise à jour du modèle global\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rsa_manager):\n",
    "        self.rsa_manager = rsa_manager\n",
    "        self.model = create_cnn_model()\n",
    "    \n",
    "    def get_weights(self):\n",
    "        \"\"\"Retourne les poids globaux.\"\"\"\n",
    "        return self.model.get_weights()\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        \"\"\"Met à jour les poids globaux.\"\"\"\n",
    "        self.model.set_weights(weights)\n",
    "    \n",
    "    def verify_and_aggregate(self, client_updates):\n",
    "        \"\"\"\n",
    "        Vérifie les signatures et agrège les mises à jour.\n",
    "        \n",
    "        Args:\n",
    "            client_updates: Liste de tuples (client_id, masked_update, signature)\n",
    "        \n",
    "        Returns:\n",
    "            aggregated_update: Moyenne des mises à jour vérifiées\n",
    "        \"\"\"\n",
    "        verified_updates = []\n",
    "        \n",
    "        print(\"  Vérification des signatures:\")\n",
    "        for client_id, masked_update, signature in client_updates:\n",
    "            # Récupérer la clé publique du client\n",
    "            public_key = self.rsa_manager.get_public_key(client_id)\n",
    "            \n",
    "            # Vérifier la signature\n",
    "            is_valid = self.rsa_manager.verify_signature(\n",
    "                masked_update, signature, public_key\n",
    "            )\n",
    "            \n",
    "            if is_valid:\n",
    "                print(f\"     Client {client_id}: Signature valide\")\n",
    "                verified_updates.append(masked_update)\n",
    "            else:\n",
    "                print(f\"     Client {client_id}: Signature INVALIDE - Rejeté\")\n",
    "        \n",
    "        if len(verified_updates) == 0:\n",
    "            raise ValueError(\"Aucune mise à jour valide!\")\n",
    "        \n",
    "        # Agrégation: moyenne des mises à jour\n",
    "        # Les masques pairwise s'annulent automatiquement!\n",
    "        aggregated_update = [\n",
    "            np.mean([update[i] for update in verified_updates], axis=0)\n",
    "            for i in range(len(verified_updates[0]))\n",
    "        ]\n",
    "        \n",
    "        print(f\"   {len(verified_updates)}/{len(client_updates)} mises à jour agrégées\")\n",
    "        \n",
    "        return aggregated_update\n",
    "    \n",
    "    def update_global_model(self, aggregated_update):\n",
    "        \"\"\"\n",
    "        Met à jour le modèle global: w_new = w_old + Δw_avg\n",
    "        \n",
    "        Args:\n",
    "            aggregated_update: Mise à jour agrégée\n",
    "        \"\"\"\n",
    "        current_weights = self.get_weights()\n",
    "        new_weights = [\n",
    "            current_w + update\n",
    "            for current_w, update in zip(current_weights, aggregated_update)\n",
    "        ]\n",
    "        self.set_weights(new_weights)\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        \"\"\"Évalue le modèle global.\"\"\"\n",
    "        loss, accuracy = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "        return loss, accuracy\n",
    "\n",
    "print(\" Classe FederatedServer définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline_section",
   "metadata": {},
   "source": [
    "## 9. Baselines de Comparaison\n",
    "\n",
    "Avant le Federated Learning, nous allons établir deux baselines:\n",
    "1. **Apprentissage Centralisé** (100% des données)\n",
    "2. **Un seul client** (1/N des données)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "centralized_baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BASELINE 1: APPRENTISSAGE CENTRALISÉ\n",
      "======================================================================\n",
      "Entraînement avec 100% des données (60000 échantillons)\n",
      "\n",
      "Entraînement en cours...\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2193 - accuracy: 0.9327 - val_loss: 0.0563 - val_accuracy: 0.9827\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0836 - accuracy: 0.9745 - val_loss: 0.0431 - val_accuracy: 0.9870\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0664 - accuracy: 0.9794 - val_loss: 0.0377 - val_accuracy: 0.9902\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0554 - accuracy: 0.9825 - val_loss: 0.0357 - val_accuracy: 0.9893\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0517 - accuracy: 0.9834 - val_loss: 0.0318 - val_accuracy: 0.9910\n",
      "\n",
      "Évaluation sur le test set...\n",
      "\n",
      " Résultats - Centralisé:\n",
      "  Accuracy: 0.9902\n",
      "  F1-Score: 0.9902\n",
      "\n",
      "Historique d'entraînement:\n",
      "  Epoch 1: Loss = 0.2193, Accuracy = 0.9327\n",
      "  Epoch 2: Loss = 0.0836, Accuracy = 0.9745\n",
      "  Epoch 3: Loss = 0.0664, Accuracy = 0.9794\n",
      "  Epoch 4: Loss = 0.0554, Accuracy = 0.9825\n",
      "  Epoch 5: Loss = 0.0517, Accuracy = 0.9834\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BASELINE 1: APPRENTISSAGE CENTRALISÉ (100% DES DONNÉES)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE 1: APPRENTISSAGE CENTRALISÉ\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Entraînement avec 100% des données ({len(x_train)} échantillons)\\n\")\n",
    "\n",
    "# Créer et entraîner le modèle centralisé\n",
    "model_centralized = create_cnn_model()\n",
    "\n",
    "print(\"Entraînement en cours...\")\n",
    "history_centralized = model_centralized.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_ROUNDS,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Évaluation\n",
    "print(\"\\nÉvaluation sur le test set...\")\n",
    "y_pred_centralized = model_centralized.predict(x_test, verbose=0)\n",
    "y_pred_centralized_classes = np.argmax(y_pred_centralized, axis=1)\n",
    "\n",
    "accuracy_centralized = accuracy_score(y_test_classes, y_pred_centralized_classes)\n",
    "f1_centralized = f1_score(y_test_classes, y_pred_centralized_classes, average='weighted')\n",
    "\n",
    "print(f\"\\n Résultats - Centralisé:\")\n",
    "print(f\"  Accuracy: {accuracy_centralized:.4f}\")\n",
    "print(f\"  F1-Score: {f1_centralized:.4f}\")\n",
    "\n",
    "# Historique\n",
    "print(f\"\\nHistorique d'entraînement:\")\n",
    "for epoch in range(NUM_ROUNDS):\n",
    "    print(f\"  Epoch {epoch+1}: \"\n",
    "          f\"Loss = {history_centralized.history['loss'][epoch]:.4f}, \"\n",
    "          f\"Accuracy = {history_centralized.history['accuracy'][epoch]:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "single_client_baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BASELINE 2: UN SEUL CLIENT\n",
      "======================================================================\n",
      "Entraînement avec 1/20 des données (3000 échantillons)\n",
      "\n",
      "Entraînement en cours...\n",
      "Epoch 1/5\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 1.3269 - accuracy: 0.5767 - val_loss: 0.4765 - val_accuracy: 0.8500\n",
      "Epoch 2/5\n",
      "85/85 [==============================] - 1s 7ms/step - loss: 0.4376 - accuracy: 0.8619 - val_loss: 0.2557 - val_accuracy: 0.9300\n",
      "Epoch 3/5\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 0.2786 - accuracy: 0.9148 - val_loss: 0.1812 - val_accuracy: 0.9567\n",
      "Epoch 4/5\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 0.2241 - accuracy: 0.9319 - val_loss: 0.1458 - val_accuracy: 0.9533\n",
      "Epoch 5/5\n",
      "85/85 [==============================] - 1s 6ms/step - loss: 0.1816 - accuracy: 0.9463 - val_loss: 0.1243 - val_accuracy: 0.9533\n",
      "\n",
      "Évaluation sur le test set...\n",
      "\n",
      " Résultats - Client unique:\n",
      "  Accuracy: 0.9555\n",
      "  F1-Score: 0.9555\n",
      "\n",
      "Historique d'entraînement:\n",
      "  Epoch 1: Loss = 1.3269, Accuracy = 0.5767\n",
      "  Epoch 2: Loss = 0.4376, Accuracy = 0.8619\n",
      "  Epoch 3: Loss = 0.2786, Accuracy = 0.9148\n",
      "  Epoch 4: Loss = 0.2241, Accuracy = 0.9319\n",
      "  Epoch 5: Loss = 0.1816, Accuracy = 0.9463\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BASELINE 2: UN SEUL CLIENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE 2: UN SEUL CLIENT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Entraînement avec 1/{NUM_CLIENTS} des données ({len(client_datasets[0][0])} échantillons)\\n\")\n",
    "\n",
    "# Créer et entraîner le modèle avec les données d'un seul client\n",
    "model_single = create_cnn_model()\n",
    "single_client_x, single_client_y = client_datasets[0]\n",
    "\n",
    "print(\"Entraînement en cours...\")\n",
    "history_single = model_single.fit(\n",
    "    single_client_x, single_client_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_ROUNDS,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Évaluation\n",
    "print(\"\\nÉvaluation sur le test set...\")\n",
    "y_pred_single = model_single.predict(x_test, verbose=0)\n",
    "y_pred_single_classes = np.argmax(y_pred_single, axis=1)\n",
    "\n",
    "accuracy_single = accuracy_score(y_test_classes, y_pred_single_classes)\n",
    "f1_single = f1_score(y_test_classes, y_pred_single_classes, average='weighted')\n",
    "\n",
    "print(f\"\\n Résultats - Client unique:\")\n",
    "print(f\"  Accuracy: {accuracy_single:.4f}\")\n",
    "print(f\"  F1-Score: {f1_single:.4f}\")\n",
    "\n",
    "# Historique\n",
    "print(f\"\\nHistorique d'entraînement:\")\n",
    "for epoch in range(NUM_ROUNDS):\n",
    "    print(f\"  Epoch {epoch+1}: \"\n",
    "          f\"Loss = {history_single.history['loss'][epoch]:.4f}, \"\n",
    "          f\"Accuracy = {history_single.history['accuracy'][epoch]:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 10. Initialisation du Système Fédéré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "setup_system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INITIALISATION DU SYSTÈME\n",
      "======================================================================\n",
      "\n",
      "1. Génération des clés RSA pour chaque client...\n",
      "   Client 0: Clés RSA générées\n",
      "   Client 1: Clés RSA générées\n",
      "   Client 2: Clés RSA générées\n",
      "   Client 3: Clés RSA générées\n",
      "   Client 4: Clés RSA générées\n",
      "   Client 5: Clés RSA générées\n",
      "   Client 6: Clés RSA générées\n",
      "   Client 7: Clés RSA générées\n",
      "   Client 8: Clés RSA générées\n",
      "   Client 9: Clés RSA générées\n",
      "   Client 10: Clés RSA générées\n",
      "   Client 11: Clés RSA générées\n",
      "   Client 12: Clés RSA générées\n",
      "   Client 13: Clés RSA générées\n",
      "   Client 14: Clés RSA générées\n",
      "   Client 15: Clés RSA générées\n",
      "   Client 16: Clés RSA générées\n",
      "   Client 17: Clés RSA générées\n",
      "   Client 18: Clés RSA générées\n",
      "   Client 19: Clés RSA générées\n",
      "\n",
      "2. Génération des clés Diffie-Hellman pour chaque client...\n",
      "   Client 0: Clés DH générées\n",
      "   Client 1: Clés DH générées\n",
      "   Client 2: Clés DH générées\n",
      "   Client 3: Clés DH générées\n",
      "   Client 4: Clés DH générées\n",
      "   Client 5: Clés DH générées\n",
      "   Client 6: Clés DH générées\n",
      "   Client 7: Clés DH générées\n",
      "   Client 8: Clés DH générées\n",
      "   Client 9: Clés DH générées\n",
      "   Client 10: Clés DH générées\n",
      "   Client 11: Clés DH générées\n",
      "   Client 12: Clés DH générées\n",
      "   Client 13: Clés DH générées\n",
      "   Client 14: Clés DH générées\n",
      "   Client 15: Clés DH générées\n",
      "   Client 16: Clés DH générées\n",
      "   Client 17: Clés DH générées\n",
      "   Client 18: Clés DH générées\n",
      "   Client 19: Clés DH générées\n",
      "\n",
      "3. Création des clients...\n",
      "   Client 0 créé\n",
      "   Client 1 créé\n",
      "   Client 2 créé\n",
      "   Client 3 créé\n",
      "   Client 4 créé\n",
      "   Client 5 créé\n",
      "   Client 6 créé\n",
      "   Client 7 créé\n",
      "   Client 8 créé\n",
      "   Client 9 créé\n",
      "   Client 10 créé\n",
      "   Client 11 créé\n",
      "   Client 12 créé\n",
      "   Client 13 créé\n",
      "   Client 14 créé\n",
      "   Client 15 créé\n",
      "   Client 16 créé\n",
      "   Client 17 créé\n",
      "   Client 18 créé\n",
      "   Client 19 créé\n",
      "\n",
      "4. Création du serveur...\n",
      "   Serveur créé\n",
      "\n",
      "======================================================================\n",
      " SYSTÈME INITIALISÉ\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INITIALISATION DU SYSTÈME FL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INITIALISATION DU SYSTÈME\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Créer les gestionnaires\n",
    "rsa_manager = RSAManager()\n",
    "sec_agg = SecureAggregation(NUM_CLIENTS)\n",
    "\n",
    "print(\"\\n1. Génération des clés RSA pour chaque client...\")\n",
    "for client_id in range(NUM_CLIENTS):\n",
    "    rsa_manager.generate_keypair(client_id)\n",
    "    print(f\"   Client {client_id}: Clés RSA générées\")\n",
    "\n",
    "print(\"\\n2. Génération des clés Diffie-Hellman pour chaque client...\")\n",
    "for client_id in range(NUM_CLIENTS):\n",
    "    sec_agg.generate_dh_keypair(client_id)\n",
    "    print(f\"   Client {client_id}: Clés DH générées\")\n",
    "\n",
    "# 2. Créer les clients\n",
    "print(\"\\n3. Création des clients...\")\n",
    "clients = []\n",
    "for client_id in range(NUM_CLIENTS):\n",
    "    client = FederatedClient(\n",
    "        client_id=client_id,\n",
    "        data=client_datasets[client_id],\n",
    "        rsa_manager=rsa_manager,\n",
    "        sec_agg=sec_agg\n",
    "    )\n",
    "    clients.append(client)\n",
    "    print(f\"   Client {client_id} créé\")\n",
    "\n",
    "# 3. Créer le serveur\n",
    "print(\"\\n4. Création du serveur...\")\n",
    "server = FederatedServer(rsa_manager)\n",
    "print(\"   Serveur créé\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" SYSTÈME INITIALISÉ\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training",
   "metadata": {},
   "source": [
    "## 11. Entraînement Fédéré avec Secure Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "federated_training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DÉMARRAGE DE L'ENTRAÎNEMENT FÉDÉRÉ\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "ROUND 1/5\n",
      "======================================================================\n",
      "\n",
      " Distribution des poids globaux...\n",
      "   Poids distribués à tous les clients\n",
      "\n",
      " Entraînement local...\n",
      "   20 clients entraînés\n",
      "\n",
      " Préparation des mises à jour (Δw masqué + signature)...\n",
      "   20 mises à jour préparées\n",
      "\n",
      " Agrégation sécurisée sur le serveur...\n",
      "  Vérification des signatures:\n",
      "     Client 0: Signature valide\n",
      "     Client 1: Signature valide\n",
      "     Client 2: Signature valide\n",
      "     Client 3: Signature valide\n",
      "     Client 4: Signature valide\n",
      "     Client 5: Signature valide\n",
      "     Client 6: Signature valide\n",
      "     Client 7: Signature valide\n",
      "     Client 8: Signature valide\n",
      "     Client 9: Signature valide\n",
      "     Client 10: Signature valide\n",
      "     Client 11: Signature valide\n",
      "     Client 12: Signature valide\n",
      "     Client 13: Signature valide\n",
      "     Client 14: Signature valide\n",
      "     Client 15: Signature valide\n",
      "     Client 16: Signature valide\n",
      "     Client 17: Signature valide\n",
      "     Client 18: Signature valide\n",
      "     Client 19: Signature valide\n",
      "   20/20 mises à jour agrégées\n",
      "\n",
      " Mise à jour du modèle global...\n",
      "   Modèle global mis à jour\n",
      "\n",
      " Évaluation...\n",
      "  Loss: 0.3607\n",
      "  Accuracy: 0.9113\n",
      "\n",
      "======================================================================\n",
      "ROUND 2/5\n",
      "======================================================================\n",
      "\n",
      " Distribution des poids globaux...\n",
      "   Poids distribués à tous les clients\n",
      "\n",
      " Entraînement local...\n",
      "   20 clients entraînés\n",
      "\n",
      " Préparation des mises à jour (Δw masqué + signature)...\n",
      "   20 mises à jour préparées\n",
      "\n",
      " Agrégation sécurisée sur le serveur...\n",
      "  Vérification des signatures:\n",
      "     Client 0: Signature valide\n",
      "     Client 1: Signature valide\n",
      "     Client 2: Signature valide\n",
      "     Client 3: Signature valide\n",
      "     Client 4: Signature valide\n",
      "     Client 5: Signature valide\n",
      "     Client 6: Signature valide\n",
      "     Client 7: Signature valide\n",
      "     Client 8: Signature valide\n",
      "     Client 9: Signature valide\n",
      "     Client 10: Signature valide\n",
      "     Client 11: Signature valide\n",
      "     Client 12: Signature valide\n",
      "     Client 13: Signature valide\n",
      "     Client 14: Signature valide\n",
      "     Client 15: Signature valide\n",
      "     Client 16: Signature valide\n",
      "     Client 17: Signature valide\n",
      "     Client 18: Signature valide\n",
      "     Client 19: Signature valide\n",
      "   20/20 mises à jour agrégées\n",
      "\n",
      " Mise à jour du modèle global...\n",
      "   Modèle global mis à jour\n",
      "\n",
      " Évaluation...\n",
      "  Loss: 0.1992\n",
      "  Accuracy: 0.9459\n",
      "\n",
      "======================================================================\n",
      "ROUND 3/5\n",
      "======================================================================\n",
      "\n",
      " Distribution des poids globaux...\n",
      "   Poids distribués à tous les clients\n",
      "\n",
      " Entraînement local...\n",
      "   20 clients entraînés\n",
      "\n",
      " Préparation des mises à jour (Δw masqué + signature)...\n",
      "   20 mises à jour préparées\n",
      "\n",
      " Agrégation sécurisée sur le serveur...\n",
      "  Vérification des signatures:\n",
      "     Client 0: Signature valide\n",
      "     Client 1: Signature valide\n",
      "     Client 2: Signature valide\n",
      "     Client 3: Signature valide\n",
      "     Client 4: Signature valide\n",
      "     Client 5: Signature valide\n",
      "     Client 6: Signature valide\n",
      "     Client 7: Signature valide\n",
      "     Client 8: Signature valide\n",
      "     Client 9: Signature valide\n",
      "     Client 10: Signature valide\n",
      "     Client 11: Signature valide\n",
      "     Client 12: Signature valide\n",
      "     Client 13: Signature valide\n",
      "     Client 14: Signature valide\n",
      "     Client 15: Signature valide\n",
      "     Client 16: Signature valide\n",
      "     Client 17: Signature valide\n",
      "     Client 18: Signature valide\n",
      "     Client 19: Signature valide\n",
      "   20/20 mises à jour agrégées\n",
      "\n",
      " Mise à jour du modèle global...\n",
      "   Modèle global mis à jour\n",
      "\n",
      " Évaluation...\n",
      "  Loss: 0.1521\n",
      "  Accuracy: 0.9570\n",
      "\n",
      "======================================================================\n",
      "ROUND 4/5\n",
      "======================================================================\n",
      "\n",
      " Distribution des poids globaux...\n",
      "   Poids distribués à tous les clients\n",
      "\n",
      " Entraînement local...\n",
      "   20 clients entraînés\n",
      "\n",
      " Préparation des mises à jour (Δw masqué + signature)...\n",
      "   20 mises à jour préparées\n",
      "\n",
      " Agrégation sécurisée sur le serveur...\n",
      "  Vérification des signatures:\n",
      "     Client 0: Signature valide\n",
      "     Client 1: Signature valide\n",
      "     Client 2: Signature valide\n",
      "     Client 3: Signature valide\n",
      "     Client 4: Signature valide\n",
      "     Client 5: Signature valide\n",
      "     Client 6: Signature valide\n",
      "     Client 7: Signature valide\n",
      "     Client 8: Signature valide\n",
      "     Client 9: Signature valide\n",
      "     Client 10: Signature valide\n",
      "     Client 11: Signature valide\n",
      "     Client 12: Signature valide\n",
      "     Client 13: Signature valide\n",
      "     Client 14: Signature valide\n",
      "     Client 15: Signature valide\n",
      "     Client 16: Signature valide\n",
      "     Client 17: Signature valide\n",
      "     Client 18: Signature valide\n",
      "     Client 19: Signature valide\n",
      "   20/20 mises à jour agrégées\n",
      "\n",
      " Mise à jour du modèle global...\n",
      "   Modèle global mis à jour\n",
      "\n",
      " Évaluation...\n",
      "  Loss: 0.1260\n",
      "  Accuracy: 0.9630\n",
      "\n",
      "======================================================================\n",
      "ROUND 5/5\n",
      "======================================================================\n",
      "\n",
      " Distribution des poids globaux...\n",
      "   Poids distribués à tous les clients\n",
      "\n",
      " Entraînement local...\n",
      "   20 clients entraînés\n",
      "\n",
      " Préparation des mises à jour (Δw masqué + signature)...\n",
      "   20 mises à jour préparées\n",
      "\n",
      " Agrégation sécurisée sur le serveur...\n",
      "  Vérification des signatures:\n",
      "     Client 0: Signature valide\n",
      "     Client 1: Signature valide\n",
      "     Client 2: Signature valide\n",
      "     Client 3: Signature valide\n",
      "     Client 4: Signature valide\n",
      "     Client 5: Signature valide\n",
      "     Client 6: Signature valide\n",
      "     Client 7: Signature valide\n",
      "     Client 8: Signature valide\n",
      "     Client 9: Signature valide\n",
      "     Client 10: Signature valide\n",
      "     Client 11: Signature valide\n",
      "     Client 12: Signature valide\n",
      "     Client 13: Signature valide\n",
      "     Client 14: Signature valide\n",
      "     Client 15: Signature valide\n",
      "     Client 16: Signature valide\n",
      "     Client 17: Signature valide\n",
      "     Client 18: Signature valide\n",
      "     Client 19: Signature valide\n",
      "   20/20 mises à jour agrégées\n",
      "\n",
      " Mise à jour du modèle global...\n",
      "   Modèle global mis à jour\n",
      "\n",
      " Évaluation...\n",
      "  Loss: 0.1107\n",
      "  Accuracy: 0.9671\n",
      "\n",
      "======================================================================\n",
      " ENTRAÎNEMENT TERMINÉ\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ENTRAÎNEMENT FÉDÉRÉ\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DÉMARRAGE DE L'ENTRAÎNEMENT FÉDÉRÉ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history = {\n",
    "    'round': [],\n",
    "    'loss': [],\n",
    "    'accuracy': []\n",
    "}\n",
    "\n",
    "for round_num in range(NUM_ROUNDS):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ROUND {round_num + 1}/{NUM_ROUNDS}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # 1. Distribuer les poids globaux\n",
    "    print(\"\\n Distribution des poids globaux...\")\n",
    "    global_weights = server.get_weights()\n",
    "    for client in clients:\n",
    "        client.set_weights(global_weights)\n",
    "    print(\"   Poids distribués à tous les clients\")\n",
    "    \n",
    "    # 2. Entraînement local\n",
    "    print(\"\\n Entraînement local...\")\n",
    "    for client in clients:\n",
    "        client.train(epochs=LOCAL_EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "    print(f\"   {NUM_CLIENTS} clients entraînés\")\n",
    "    \n",
    "    # 3. Préparation des mises à jour (calcul Δw + masquage + signature)\n",
    "    print(\"\\n Préparation des mises à jour (Δw masqué + signature)...\")\n",
    "    client_updates = []\n",
    "    for client in clients:\n",
    "        masked_update, signature = client.prepare_update(global_weights)\n",
    "        client_updates.append((client.client_id, masked_update, signature))\n",
    "    print(f\"   {len(client_updates)} mises à jour préparées\")\n",
    "    \n",
    "    # 4. Agrégation sécurisée côté serveur\n",
    "    print(\"\\n Agrégation sécurisée sur le serveur...\")\n",
    "    aggregated_update = server.verify_and_aggregate(client_updates)\n",
    "    \n",
    "    # 5. Mise à jour du modèle global\n",
    "    print(\"\\n Mise à jour du modèle global...\")\n",
    "    server.update_global_model(aggregated_update)\n",
    "    print(\"   Modèle global mis à jour\")\n",
    "    \n",
    "    # 6. Évaluation\n",
    "    print(\"\\n Évaluation...\")\n",
    "    loss, accuracy = server.evaluate(x_test, y_test)\n",
    "    print(f\"  Loss: {loss:.4f}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    history['round'].append(round_num + 1)\n",
    "    history['loss'].append(loss)\n",
    "    history['accuracy'].append(accuracy)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" ENTRAÎNEMENT TERMINÉ\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results",
   "metadata": {},
   "source": [
    "## 12. Résultats Finaux du FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "final_results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RÉSULTATS FINAUX\n",
      "======================================================================\n",
      "\n",
      "Métriques finales:\n",
      "  Accuracy: 0.9671\n",
      "  F1-Score: 0.9671\n",
      "\n",
      "Historique d'entraînement:\n",
      "  Round 1: Loss = 0.3607, Accuracy = 0.9113\n",
      "  Round 2: Loss = 0.1992, Accuracy = 0.9459\n",
      "  Round 3: Loss = 0.1521, Accuracy = 0.9570\n",
      "  Round 4: Loss = 0.1260, Accuracy = 0.9630\n",
      "  Round 5: Loss = 0.1107, Accuracy = 0.9671\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RÉSULTATS FINAUX\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RÉSULTATS FINAUX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prédictions finales\n",
    "y_pred = server.model.predict(x_test, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Métriques\n",
    "final_accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "final_f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"\\nMétriques finales:\")\n",
    "print(f\"  Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"  F1-Score: {final_f1:.4f}\")\n",
    "\n",
    "# Historique\n",
    "print(f\"\\nHistorique d'entraînement:\")\n",
    "for i in range(len(history['round'])):\n",
    "    print(f\"  Round {history['round'][i]}: \"\n",
    "          f\"Loss = {history['loss'][i]:.4f}, \"\n",
    "          f\"Accuracy = {history['accuracy'][i]:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verification",
   "metadata": {},
   "source": [
    "## 13. Vérification du Masquage Pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "verify_masking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VÉRIFICATION DU MASQUAGE PAIRWISE\n",
      "======================================================================\n",
      "\n",
      "Test: Les masques pairwise doivent s'annuler lors de l'agrégation\n",
      "\n",
      "Création de mises à jour fictives...\n",
      "Application des masques pairwise...\n",
      "Agrégation des mises à jour masquées...\n",
      "\n",
      "Résultat:\n",
      "  Déviation maximale de zéro: 0.0000000000\n",
      "   SUCCÈS: Les masques se sont correctement annulés!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VÉRIFICATION QUE LES MASQUES S'ANNULENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VÉRIFICATION DU MASQUAGE PAIRWISE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nTest: Les masques pairwise doivent s'annuler lors de l'agrégation\")\n",
    "print(\"\\nCréation de mises à jour fictives...\")\n",
    "\n",
    "# Créer des mises à jour fictives (zéros)\n",
    "dummy_shape = (10, 10)  # Forme simplifiée\n",
    "dummy_updates = [np.zeros(dummy_shape) for _ in range(NUM_CLIENTS)]\n",
    "\n",
    "# Appliquer les masques\n",
    "print(\"Application des masques pairwise...\")\n",
    "masked_updates = []\n",
    "for client_id in range(NUM_CLIENTS):\n",
    "    masked = sec_agg.mask_weights(client_id, [dummy_updates[client_id]])\n",
    "    masked_updates.append(masked[0])\n",
    "\n",
    "# Agréger\n",
    "print(\"Agrégation des mises à jour masquées...\")\n",
    "aggregated = np.mean(masked_updates, axis=0)\n",
    "\n",
    "# Vérifier\n",
    "max_deviation = np.max(np.abs(aggregated))\n",
    "print(f\"\\nRésultat:\")\n",
    "print(f\"  Déviation maximale de zéro: {max_deviation:.10f}\")\n",
    "\n",
    "if max_deviation < 1e-6:\n",
    "    print(f\"   SUCCÈS: Les masques se sont correctement annulés!\")\n",
    "else:\n",
    "    print(f\"   ERREUR: Les masques ne s'annulent pas parfaitement\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 14. Comparaison des Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "final_comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARAISON FINALE DES TROIS APPROCHES\n",
      "======================================================================\n",
      "\n",
      "Calcul des métriques pour Federated Learning...\n",
      "\n",
      "======================================================================\n",
      "TABLEAU COMPARATIF\n",
      "======================================================================\n",
      "\n",
      "Approche                            Données         Accuracy     F1-Score    \n",
      "----------------------------------------------------------------------\n",
      "1. Centralisé                       100%            0.9902       0.9902      \n",
      "2. Client unique                    1/20 = 5.0%     0.9555       0.9555      \n",
      "3. Federated Learning               20 clients      0.9671       0.9671      \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COMPARAISON FINALE DES TROIS APPROCHES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARAISON FINALE DES TROIS APPROCHES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculer les résultats du FL\n",
    "print(\"\\nCalcul des métriques pour Federated Learning...\")\n",
    "y_pred_fl = server.model.predict(x_test, verbose=0)\n",
    "y_pred_fl_classes = np.argmax(y_pred_fl, axis=1)\n",
    "accuracy_fl = accuracy_score(y_test_classes, y_pred_fl_classes)\n",
    "f1_fl = f1_score(y_test_classes, y_pred_fl_classes, average='weighted')\n",
    "\n",
    "# Tableau de comparaison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLEAU COMPARATIF\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Approche':<35} {'Données':<15} {'Accuracy':<12} {'F1-Score':<12}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'1. Centralisé':<35} {'100%':<15} {accuracy_centralized:<12.4f} {f1_centralized:<12.4f}\")\n",
    "print(f\"{'2. Client unique':<35} {f'1/{NUM_CLIENTS} = {100/NUM_CLIENTS:.1f}%':<15} {accuracy_single:<12.4f} {f1_single:<12.4f}\")\n",
    "print(f\"{'3. Federated Learning':<35} {f'{NUM_CLIENTS} clients':<15} {accuracy_fl:<12.4f} {f1_fl:<12.4f}\")\n",
    "print(\"-\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
